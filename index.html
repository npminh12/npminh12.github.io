<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" href="bootstrap.min.css">
  <script src="jquery.min.js"></script>
  <script src="bootstrap.min.js"></script>
	<script async src="https://www.googletagmanager.com/gtag/js?id=G-Q1PHCFBBTH"></script>
	<script>
	  window.dataLayer = window.dataLayer || [];
	  function gtag(){dataLayer.push(arguments);}
	  gtag('js', new Date());

	  gtag('config', 'G-Q1PHCFBBTH');
	</script>  
</head>

<P> &nbsp; <P>

<div class="container">


<h3>Phan-Minh Nguyen</h3>

<p>I received my Ph.D. from <a href="https://www.stanford.edu/">Stanford University</a> under the supervision of <a href="http://web.stanford.edu/~montanar/">Andrea Montanari</a>. Before that, I received my bachelor degree from the <a href="http://www.nus.edu.sg/">National University of Singapore</a>.

<p>My research interests are in the theory of neural networks, statistical and algorithmic inference, information theory and coding theory.

<p>[<a href="https://scholar.google.com/citations?user=lPG5fAIAAAAJ">Google Scholar</a>] [<a href="https://github.com/npminh12">Github</a>] Email: <img src="myemail.png" class="col-md-20 col-sm-20 col-xs-20" height="21" title="email" align=middle> 

</div>
</font>



<div class="container">

<P> &nbsp; <P>
<h3>Research works</h3>
(* denotes ordering by last names, ** denotes randomized ordering.)
<P> &nbsp; <P>


<p>** Limiting fluctuation and trajectorial stability of multilayer neural networks with mean field training. <a href="https://arxiv.org/abs/2110.15954">[Paper]</a><br/>
<p>H. T. Pham, P.-M. Nguyen. <b>Neural Information Processing Systems (NeurIPS)</b>, 2021.
<P> &nbsp; <P>


<p>Analysis of Feature Learning in Weight-tied Autoencoders via the Mean Field Lens. <a href="https://arxiv.org/abs/2102.08373">[Paper]</a><br/>
<p>P.-M. Nguyen. <i>Preprint, Feb 2021.</i>
<P> &nbsp; <P>


<p>* A Rigorous Framework for the Mean Field Limit of Multilayer Neural Networks.  <a href="https://arxiv.org/abs/2001.11443">[Paper]</a><br/>
<p>P.-M. Nguyen, H. T. Pham. <i>Preprint, Jan 2020. (v2 May 2021)</i>
<ul>
  <li> (Conference version) ** Global Convergence of Three-layer Neural Networks in the Mean Field Regime. <a href="https://openreview.net/forum?id=KvyxFqZS_D">[OpenReview]</a>
<p>H. T. Pham, P.-M. Nguyen. <b> International Conference on Learning Representations (ICLR)</b>, 2021. <b>Oral presentation (1.8% of submissions).</b>
  <li> (May 2021) Version 2 updated to include the following companion note:
<p>** A Note on the Global Convergence of Multilayer Neural Networks in the Mean Field Regime.  <a href="https://arxiv.org/abs/2006.09355">[Paper]</a><br/>
<p>H. T. Pham, P.-M. Nguyen. <i>Preprint, Jun 2020.</i>
  <li style="color:PURPLE";> Here is a very nice talk given by Huy T. Pham: <a href="https://www.youtube.com/watch?v=3gxDiTEE-bM">[Talk]</a></li>
</ul>
<P> &nbsp; <P>

<p>Mean Field Limit in Neural Network Learning: Autoencoders and Multilayer Networks.  <a href="https://purl.stanford.edu/tz731wp0288">[Stanford Repository]</a><br/>
<p>P.-M. Nguyen. <i>Ph.D. Thesis, 2020.</i>
<P> &nbsp; <P>

<p>Mean Field Limit of the Learning Dynamics of Multilayer Neural Networks. <a href="https://arxiv.org/abs/1902.02880">[Paper]</a><br/>
<p>P.-M. Nguyen. <i>Preprint, Feb 2019.</i>
<P> &nbsp; <P>

<p>* On Random Deep Weight-Tied Autoencoders: Exact Asymptotic Analysis, Phase Transitions and Implications to Training. <a href="https://openreview.net/forum?id=HJx54i05tX">[OpenReview]</a><br/>
<p>P. Li, P.-M. Nguyen. <b> International Conference on Learning Representations (ICLR)</b>, 2019. <b>Oral presentation (1.5% of submissions).</b>
<P> &nbsp; <P>

<p>* State Evolution for Approximate Message Passing with Non-Separable Functions. <a href="http://arxiv.org/abs/1708.03950">[Paper]</a><br/>
<p>R. Berthier, A. Montanari, P.-M. Nguyen. <b>Information and Inference: a Journal of the IMA</b>, 2019.
<P> &nbsp; <P>
	
<p>* A Mean Field View of the Landscape of Two-Layers Neural Networks. <a href="http://arxiv.org/abs/1804.06561">[Paper]</a><br/>
<p>S. Mei, A. Montanari, P.-M. Nguyen. <b>Proceedings of the National Academy of Sciences</b>, 2018.
<P> &nbsp; <P>

<p>* Universality of the Elastic Net Squared Error. <a href="elasticNet_universality_full.pdf">[Long version]</a><br/>
<p>A. Montanari, P.-M. Nguyen. <b>IEEE International Symposium on Information Theory (ISIT)</b>, Aachen, Germany, 2017.
<P> &nbsp; <P>

<p>Universality of the LASSO Cost. <a href="LASSO_cost_universality.pdf">[Note]</a><br/>
<p>P.-M. Nguyen. <i>Unpublished note, 2017.</i>
<P> &nbsp; <P>

<p>Capacity of the Energy Harvesting Channel with a Finite Battery. <a href="http://arxiv.org/abs/1506.02024">[Paper]</a><br/>
<p>D. Shaviv, P.-M. Nguyen, A. Ozgur. <b>IEEE Transactions on Information Theory</b>, 2016.
<P> &nbsp; <P>

<p>On Capacity Formulation with Stationary Inputs and Application to a Bit-Patterned Magnetic Recording Channel Model. <a href="http://arxiv.org/abs/1509.02297">[Paper]</a><br/>
<p>P.-M. Nguyen, M.A. Armand. <b>IEEE Transactions on Information Theory</b>, 2015.
<P> &nbsp; <P>


<p>Improved Codes for Synchronization Error Correction on the BPMR Channel. <a href="TMRC2014.pdf">[Extended abstract]</a><br/>
<p>P.-M. Nguyen, M.A. Armand, T. Wu. <b>The Magnetic Recording Conference (TMRC)</b>, Berkeley, USA, 2014.
<P> &nbsp; <P>

<p>On the Watermark String in the Davey-MacKay Construction.<br/>
<p>P.-M. Nguyen, M.A. Armand, T. Wu. <b>IEEE Communications Letters</b>, 2013.
<P> &nbsp; <P>

</div>


<div class="container">

<h3>Services</h3>
<p>Journal refereeing:<br/> 
	Journal of the American Statistical Association, Entropy, Mathematical Programming, IEEE Trans. Information Theory, IEEE Trans. Signal Processing, IEEE Trans. Magnetics. <br/>
<p>Conference refereeing: <br/>
	ICML, ICLR, NeurIPS, MSML, AISTATS, ISIT. (Top reviewer for ICML 2019, ICML 2020, ICLR 2021, ICLR 2022.)<br/>
<P> &nbsp; <P>

  
</html>
